{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human-in-the-Loop\n",
    "There are two main ways to interact with the team from your application:\n",
    "\n",
    "1. During a team’s run – execution of run() or run_stream(), provide feedback through a UserProxyAgent.\n",
    "\n",
    "2. Once the run terminates, provide feedback through input to the next call to run() or run_stream()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Resources Needed\n",
    "1. Azure OpenAI\n",
    "    - Deploy GPT-4o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure OpenAI Client\n",
    "Using the model client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Create the token provider\n",
    "#token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=azure_openai_deployment,\n",
    "    model=azure_openai_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key=azure_openai_key, # For key-based authentication.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UserProxyAgent - Providing Feedback During a Run\n",
    "The UserProxyAgent is a special built-in agent that acts as a proxy for a user to provide feedback to the team.\n",
    "\n",
    "To use the UserProxyAgent, you can create an instance of it and include it in the team before running the team. The team will decide when to call the UserProxyAgent to ask for feedback from the user.\n",
    "\n",
    "When UserProxyAgent is called during a run, it blocks the execution of the team until the user provides feedback or errors out. This will hold up the team’s progress and put the team in an unstable state that cannot be saved or resumed.\n",
    "\n",
    "Due to the blocking nature of this approach, it is recommended to use it only for short interactions that require immediate feedback from the user, such as asking for approval or disapproval with a button click, or an alert requiring immediate attention otherwise failing the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# Create the agents.\n",
    "# Create the primary agent.\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "# Create the critic agent.\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"Provide constructive feedback.\",\n",
    ")\n",
    "\n",
    "# Create the user proxy agent.\n",
    "user_proxy = UserProxyAgent(\"user_proxy\", input_func=input)  # Use input() to get user input from console.\n",
    "\n",
    "# Create the termination condition which will end the conversation when the user says \"APPROVE\".\n",
    "termination = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# Create the team.\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent, user_proxy], termination_condition=termination)\n",
    "\n",
    "# Run the conversation and stream to the console.\n",
    "stream = team.run_stream(task=\"Write a short poem about the fall season.\")\n",
    "# Use asyncio.run(...) when running in a script.\n",
    "await Console(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Max Turns\n",
    "\n",
    "This method allows you to pause the team for user input by setting a maximum number of turns. \n",
    "\n",
    "To implement this, set the max_turns parameter in the RoundRobinGroupChat() constructor.\n",
    "\n",
    "Once the team stops, the turn count will be reset. \n",
    "\n",
    "When you resume the team, it will start from 0 again. However, the team’s internal state will be preserved, for example, the RoundRobinGroupChat will resume from the next agent in the list with the same conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the team setting a maximum number of turns to 2.\n",
    "# One chat by agent is one turn. So 2 is needed for the two agents\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], max_turns=2)\n",
    "\n",
    "task = \"Write a short poem about the fall season.\"\n",
    "while True:\n",
    "    # Run the conversation and stream to the console.\n",
    "    stream = team.run_stream(task=task)\n",
    "    # Use asyncio.run(...) when running in a script.\n",
    "    await Console(stream)\n",
    "    # Get the user response.\n",
    "    task = input(\"Enter your feedback (type 'exit' to leave): \")\n",
    "    if task.lower().strip() == \"exit\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HandoffTermination \n",
    "HandoffTermination stops the team when an agent sends a HandoffMessage message.\n",
    "\n",
    "Note: The model used with AssistantAgent must support tool call to use the handoff feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.base import Handoff\n",
    "from autogen_agentchat.conditions import HandoffTermination\n",
    "\n",
    "# Create the agents.\n",
    "# Create the primary agent.\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "# Create the critic agent.\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"Provide constructive feedback first then transfer to user.\",\n",
    "    handoffs=[Handoff(target=\"user\", message=\"Transfer to user.\")],\n",
    ")\n",
    "\n",
    "# Define a termination condition that checks for handoff message targetting helper OR text \"APPROVE\".\n",
    "handoff_termination = HandoffTermination(target=\"user\")\n",
    "\n",
    "# Create the team.\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=handoff_termination)\n",
    "\n",
    "# Run the conversation and stream to the console.\n",
    "stream = team.run_stream(task=\"Write a short poem about the fall season.\")\n",
    "# Use asyncio.run(...) when running in a script.\n",
    "await Console(stream)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
