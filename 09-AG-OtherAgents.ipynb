{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen Other Agents\n",
    "\n",
    "Samples of other preset agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Resources Needed\n",
    "1. Azure OpenAI\n",
    "    - Deploy GPT-4o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"autogen-ext[openai]==0.4.0.dev13\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure OpenAI Client\n",
    "Using the model client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient, OpenAIChatCompletionClient\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Create the token provider\n",
    "#token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=azure_openai_deployment,\n",
    "    model=azure_openai_deployment,\n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    # azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    api_key=azure_openai_key, # For key-based authentication.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Web Surfer\n",
    "MultimodalWebSurfer is a multimodal agent that acts as a web surfer that can search the web and visit web pages.\n",
    "\n",
    "Note: Need to run in terminal: playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library\n",
    "%pip install \"autogen-ext[web-surfer]==0.4.0.dev13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Date: 2025-02-14\n",
      "---------- user ----------\n",
      "Today is 2025-02-14. What is the latest Lakers game and did they win?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:412: DeprecationWarning: capabilities is deprecated, use model_info instead\n",
      "  if self.capabilities[\"vision\"] is False:\n",
      "/home/codespace/.python/current/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:427: DeprecationWarning: capabilities is deprecated, use model_info instead\n",
      "  if self.capabilities[\"json_output\"] is False and json_output is True:\n",
      "/home/codespace/.python/current/lib/python3.12/site-packages/autogen_ext/models/openai/_openai_client.py:433: DeprecationWarning: capabilities is deprecated, use model_info instead\n",
      "  if self.capabilities[\"function_calling\"] is False and len(tools) > 0:\n",
      "/home/codespace/.python/current/lib/python3.12/site-packages/autogen_ext/agents/web_surfer/_multimodal_web_surfer.py:503: UserWarning: Resolved model mismatch: gpt-4o-2024-08-06 != gpt-4o-2024-05-13. Model mapping may be incorrect.\n",
      "  response = await self._model_client.create(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- MultimodalWebSurfer ----------\n",
      "I typed 'latest Lakers game result' into '0 characters out of 2000'.\n",
      "\n",
      " Here is a screenshot of the webpage: [latest Lakers game result - Search](https://www.bing.com/search?q=latest+Lakers+game+result&form=QBLH&sp=-1&lq=0&pq=&sc=0-0&qs=n&sk=&cvid=E9F53A0ED4B746D488B5296E94009C47&ghsh=0&ghacc=0&ghpl=).\n",
      " The viewport shows 22% of the webpage, and is positioned at the top of the page \n",
      "The following metadata was extracted from the webpage:\n",
      "\n",
      "{\n",
      "    \"meta_tags\": {\n",
      "        \"referrer\": \"origin-when-cross-origin\",\n",
      "        \"SystemEntropyOriginTrialToken\": \"A5is4nwJJVnhaJpUr1URgj4vvAXSiHoK0VBbM9fawMskbDUj9WUREpa3JzGAo6xd1Cp2voQEG1h6NQ71AsMznU8AAABxeyJvcmlnaW4iOiJodHRwczovL3d3dy5iaW5nLmNvbTo0NDMiLCJmZWF0dXJlIjoiTXNVc2VyQWdlbnRMYXVuY2hOYXZUeXBlIiwiZXhwaXJ5IjoxNzUzNzQ3MjAwLCJpc1N1YmRvbWFpbiI6dHJ1ZX0=\",\n",
      "        \"og:description\": \"Intelligent search from Bing makes it easier to quickly find what you\\u2019re looking for and rewards you.\",\n",
      "        \"og:site_name\": \"Bing\",\n",
      "        \"og:title\": \"latest Lakers game result - Bing\",\n",
      "        \"og:url\": \"https://www.bing.com/search?q=latest+Lakers+game+result&form=QBLH&sp=-1&lq=0&pq=&sc=0-0&qs=n&sk=&cvid=E9F53A0ED4B746D488B5296E94009C47&ghsh=0&ghacc=0&ghpl=\",\n",
      "        \"fb:app_id\": \"3732605936979161\",\n",
      "        \"og:image\": \"http://www.bing.com/sa/simg/facebook_sharing_5.png\",\n",
      "        \"og:type\": \"website\",\n",
      "        \"og:image:width\": \"600\",\n",
      "        \"og:image:height\": \"315\"\n",
      "    }\n",
      "}\n",
      "\n",
      "The first 50 lines of the page text is:\n",
      "\n",
      "Skip to content\n",
      "latest Lakers game result\n",
      "Deep search\n",
      "ALLCOPILOTNEWSIMAGESVIDEOSMAPS\n",
      "MORE\n",
      "TOOLS\n",
      "About 2,750,000 results\n",
      "Los Angeles Lakers\n",
      "5th in Western Conference · NBA\n",
      "GAMES\n",
      "NEWS\n",
      "STANDINGS\n",
      "PLAYERS\n",
      "Yesterday\n",
      "NBA\n",
      "Final\n",
      "Lakers\n",
      "Away, 32-20\n",
      "119\n",
      "-\n",
      "131\n",
      "Jazz\n",
      "Home, 13-41\n",
      "Team\t1\t2\t3\t4\tT\n",
      "Lakers\n",
      "\t30\t26\t30\t33\t119\n",
      "Jazz\n",
      "\t33\t31\t40\t27\t131\n",
      "Delta Center, Salt Lake City\n",
      "Tue, Feb 11 · Final\n",
      "NBA\n",
      "Jazz\n",
      "113\n",
      "Lakers\n",
      "132\n",
      "Sun, Feb 9 · Final\n",
      "NBA\n",
      "Pacers\n",
      "117\n",
      "Lakers\n",
      "124\n",
      "Fri, Feb 7 · Final\n",
      "NBA\n",
      "Warriors\n",
      "112\n",
      "Lakers\n",
      "120\n",
      "Wed, Feb 5 · Final\n",
      "<image>\n",
      "[Prompt tokens: 2466, Completion tokens: 44]\n",
      "---------- MultimodalWebSurfer ----------\n",
      "The latest Lakers game was against the Jazz, where they lost with a score of 119-131.\n",
      "[Prompt tokens: 7630, Completion tokens: 22]\n",
      "---------- MultimodalWebSurfer ----------\n",
      "I clicked 'Tue, Feb 11 · Final\n",
      "NBA\n",
      "Jazz\n",
      "113\n",
      "Lakers\n",
      "132'.\n",
      "\n",
      " Here is a screenshot of the webpage: [Utah Jazz vs Los Angeles Lakers - Search](https://www.bing.com/sportsdetails?q=Utah%20Jazz%20vs%20Los%20Angeles%20Lakers&gameid=SportRadar_Basketball_NBA_2024_Game_e318dc5f-74eb-4a38-bd0f-0ce53acdd77b&league=Basketball_NBA&scenario=GameCenter&intent=Game&iscelebratedgame=False&TimezoneId=Singapore%20Standard%20Time&sport=Basketball&team=SportRadar_Basketball_NBA_2024_Team_583ecae2-fb46-11e1-82cb-f4ce4684ea4c&team2=SportRadar_Basketball_NBA_2024_Team_583ece50-fb46-11e1-82cb-f4ce4684ea4c&venueid={%22id%22:%22SportRadar_Basketball_NBA_2024_Venue_792ec100-691e-5e16-8ef8-79b2b6ee38ba%22}:version-1&segment=sports&isl2=true&).\n",
      " The viewport shows 76% of the webpage, and is positioned at the top of the page \n",
      "The following metadata was extracted from the webpage:\n",
      "\n",
      "{\n",
      "    \"meta_tags\": {\n",
      "        \"viewport\": \"width=device-width, minimum-scale=1.0, initial-scale=1.0, maximum-scale=1.0, user-scalable=no\",\n",
      "        \"referrer\": \"origin-when-cross-origin\"\n",
      "    }\n",
      "}\n",
      "\n",
      "The first 50 lines of the page text is:\n",
      "\n",
      "简体中文\n",
      "3\n",
      "Jazz vs Lakers\n",
      "Tue, Feb 11\n",
      "NBA\n",
      "Final\n",
      "Jazz\n",
      "Away, 13-41\n",
      "113\n",
      "-\n",
      "132\n",
      "Lakers\n",
      "Home, 32-20\n",
      "Team\t1\t2\t3\t4\tT\n",
      "Jazz\n",
      "\t25\t22\t28\t38\t113\n",
      "Lakers\n",
      "\t37\t35\t28\t32\t132\n",
      "Crypto.com Arena, Los Angeles\n",
      "Luka Dončić's First Bucket As A Laker! | February 10, 2025\n",
      "GAME LEADERS\n",
      "GAME STATS\n",
      "BOX SCORE\n",
      "Jazz\n",
      "Points\n",
      "John Collins\n",
      "Power Forward\n",
      "Pts\n",
      "17\n",
      "Reb\n",
      "11\n",
      "Ast\n",
      "0\n",
      "Rebounds\n",
      "Walker Kessler\n",
      "Center\n",
      "Pts\n",
      "13\n",
      "Reb\n",
      "12\n",
      "Ast\n",
      "2\n",
      "Assists\n",
      "Isaiah Collier\n",
      "Point Guard\n",
      "Pts\n",
      "13\n",
      "Reb\n",
      "<image>\n",
      "[Prompt tokens: 7900, Completion tokens: 29]\n",
      "---------- MultimodalWebSurfer ----------\n",
      "The most recent Lakers game was a victory for the Lakers against the Jazz with a score of 132-113.\n",
      "[Prompt tokens: 4629, Completion tokens: 24]\n",
      "---------- MultimodalWebSurfer ----------\n",
      "The most recent Lakers game, played on February 11, 2025, resulted in a win for the Lakers with a final score of 132-113 against the Jazz.\n",
      "[Prompt tokens: 4663, Completion tokens: 37]\n",
      "---------- MultimodalWebSurfer ----------\n",
      "The most recent Lakers game on February 11, 2025, resulted in a win for the Lakers with a final score of 132-113 against the Jazz.\n",
      "[Prompt tokens: 4710, Completion tokens: 35]\n",
      "---------- MultimodalWebSurfer ----------\n",
      "The latest Lakers game was against the Jazz on February 11, 2025, where the Lakers won with a score of 132-113.\n",
      "[Prompt tokens: 4755, Completion tokens: 31]\n",
      "---------- MultimodalWebSurfer ----------\n",
      "The latest Lakers game was against the Jazz on February 11, 2025, and the Lakers won with a score of 132-113.\n",
      "[Prompt tokens: 4796, Completion tokens: 31]\n",
      "---------- MultimodalWebSurfer ----------\n",
      "The latest Lakers game was a win, with a final score of 132-113 against the Utah Jazz.\n",
      "[Prompt tokens: 4837, Completion tokens: 23]\n",
      "---------- MultimodalWebSurfer ----------\n",
      "The latest Lakers game, played on February 11, 2025, resulted in a win for the Lakers with a final score of 132-113 against the Jazz.\n",
      "[Prompt tokens: 4870, Completion tokens: 36]\n",
      "---------- MultimodalWebSurfer ----------\n",
      "The latest Lakers game was on February 11, 2025, where they won against the Jazz with a score of 132-113.\n",
      "[Prompt tokens: 4916, Completion tokens: 30]\n",
      "---------- MultimodalWebSurfer ----------\n",
      "The latest Lakers game was on February 11, 2025, and they won against the Jazz with a score of 132-113.\n",
      "[Prompt tokens: 4956, Completion tokens: 30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n",
      "pipe closed by peer or os.write(pipe, data) raised exception.\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Run the team and stream messages to the console\u001b[39;00m\n\u001b[1;32m     22\u001b[0m stream \u001b[38;5;241m=\u001b[39m agent_team\u001b[38;5;241m.\u001b[39mrun_stream(task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToday is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. What is the latest Lakers game and did they win?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m Console(stream)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Close the browser controlled by the agent\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m web_surfer_agent\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/autogen_agentchat/ui/_console.py:49\u001b[0m, in \u001b[0;36mConsole\u001b[0;34m(stream, no_inline_images)\u001b[0m\n\u001b[1;32m     45\u001b[0m total_usage \u001b[38;5;241m=\u001b[39m RequestUsage(prompt_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, completion_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     47\u001b[0m last_processed: Optional[T] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, TaskResult):\n\u001b[1;32m     51\u001b[0m         duration \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/autogen_agentchat/teams/_group_chat/_base_group_chat.py:417\u001b[0m, in \u001b[0;36mBaseGroupChat.run_stream\u001b[0;34m(self, task, cancellation_token)\u001b[0m\n\u001b[1;32m    415\u001b[0m     cancellation_token\u001b[38;5;241m.\u001b[39mlink_future(message_future)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# Wait for the next message, this will raise an exception if the task is cancelled.\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m message_future\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/asyncio/queues.py:158\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getters\u001b[38;5;241m.\u001b[39mappend(getter)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m getter\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     getter\u001b[38;5;241m.\u001b[39mcancel()  \u001b[38;5;66;03m# Just in case getter is not done yet.\u001b[39;00m\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_ext.agents.web_surfer import MultimodalWebSurfer\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "# Extract the date part\n",
    "current_date = now.date()\n",
    "print(\"Current Date:\", current_date)\n",
    "\n",
    "# Define an agent\n",
    "web_surfer_agent = MultimodalWebSurfer(\n",
    "    name=\"MultimodalWebSurfer\",\n",
    "    model_client=az_model_client,\n",
    ")\n",
    "\n",
    "# Define a team\n",
    "agent_team = RoundRobinGroupChat([web_surfer_agent], max_turns=100)\n",
    "\n",
    "# Run the team and stream messages to the console\n",
    "stream = agent_team.run_stream(task=f\"Today is {current_date}. What is the latest Lakers game and did they win?\")\n",
    "await Console(stream)\n",
    "# Close the browser controlled by the agent\n",
    "await web_surfer_agent.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Assistant Agent\n",
    "\n",
    "An agent implementation that uses the OpenAI Assistant API to generate responses.\n",
    "\n",
    "This agent leverages the OpenAI Assistant API to create AI assistants with capabilities like:\n",
    "- Code interpretation and execution\n",
    "- File handling and search\n",
    "- Custom function calling\n",
    "- Multi-turn conversations\n",
    "\n",
    "The agent maintains a thread of conversation and can use various tools including\n",
    "- Code interpreter: For executing code and working with files\n",
    "- File search: For searching through uploaded documents\n",
    "- Custom functions: For extending capabilities with user-defined tools\n",
    "\n",
    "Key Features:\n",
    "- Supports multiple file formats including code, documents, images\n",
    "- Can handle up to 128 tools per assistant\n",
    "- Maintains conversation context in threads\n",
    "- Supports file uploads for code interpreter and search\n",
    "- Vector store integration for efficient file search\n",
    "- Automatic file parsing and embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_core import CancellationToken\n",
    "from autogen_ext.agents.openai import OpenAIAssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from openai import AsyncAzureOpenAI\n",
    "\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "# Create AzureOpenAI client\n",
    "client = AsyncAzureOpenAI(azure_endpoint=azure_openai_endpoint, \n",
    "                          api_version=azure_openai_api_version, \n",
    "                          api_key=azure_openai_key)\n",
    "\n",
    "\n",
    "#### Create a vector store for file search ####\n",
    "vector_store = await client.beta.vector_stores.create(name=\"Nasa_books\")\n",
    "# Specify the folder containing the files\n",
    "folder_path = \"Data/nasabooks/\"\n",
    "# Get all file paths in the folder\n",
    "file_paths = [os.path.join(folder_path, file_name) for file_name in os.listdir(folder_path)]\n",
    "# Open file streams\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = await client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "# Close file streams\n",
    "for file in file_streams:\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)\n",
    "print(vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create an assistant with file search ####\n",
    "assistant = OpenAIAssistantAgent(\n",
    "    name=\"DataAssistant\",\n",
    "    description=\"Answer questions about data\",\n",
    "    client=client,\n",
    "    model=azure_openai_deployment,\n",
    "    instructions=\"You will answer questions about the files given to you\",\n",
    "    tools=[\"file_search\"],\n",
    "    tool_resources={\"file_search\":{\"vector_store_ids\":[vector_store.id]}}\n",
    ")\n",
    "\n",
    "# Get response from the assistant\n",
    "user_input = TextMessage(source=\"user\", content=\"What can I see in Mauritania?\")\n",
    "response = await assistant.on_messages([user_input], cancellation_token\n",
    ")\n",
    "print(response.chat_message.content)\n",
    "\n",
    "# Clean up resources\n",
    "await assistant.delete_uploaded_files(cancellation_token)\n",
    "await assistant.delete_assistant(cancellation_token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AzureOpenAI client\n",
    "client = AsyncAzureOpenAI(azure_endpoint=azure_openai_endpoint, \n",
    "                          api_version=azure_openai_api_version, \n",
    "                          api_key=azure_openai_key)\n",
    "\n",
    "# Upload the files\n",
    "file_1 = open(\"Data/population/PopulationByAdmin1.csv\", \"rb\")\n",
    "try:\n",
    "    code_interpreter_file_1 = await client.files.create(\n",
    "        file=file_1,\n",
    "        purpose='assistants'\n",
    "    )\n",
    "finally:\n",
    "    file_1.close()\n",
    "\n",
    "file_2 = open(\"Data/population/PopulationByCountry.csv\", \"rb\")\n",
    "try:\n",
    "    code_interpreter_file_2 = await client.files.create(\n",
    "        file=file_2,\n",
    "        purpose='assistants'\n",
    "    )\n",
    "finally:\n",
    "    file_2.close()\n",
    "\n",
    "\n",
    "#### Create an assistant with code interpreter ####\n",
    "assistant = OpenAIAssistantAgent(\n",
    "    name=\"DataAssistant\",\n",
    "    description=\"Answer questions about data\",\n",
    "    client=client,\n",
    "    model=azure_openai_deployment,\n",
    "    instructions=\"You will use Python to answer questions about a dataset\",\n",
    "    tools=[\"code_interpreter\"],\n",
    "    tool_resources={\"code_interpreter\":{\"file_ids\":[code_interpreter_file_1.id, code_interpreter_file_2.id]}}\n",
    ")\n",
    "\n",
    "# Get response from the assistant\n",
    "user_input = TextMessage(source=\"user\", content=\"\"\"Use the code interpreter file. \n",
    "                         Which country has the third highest population?\"\"\")\n",
    "response = await assistant.on_messages([user_input], cancellation_token\n",
    ")\n",
    "print(response.chat_message.content)\n",
    "\n",
    "# Clean up resources\n",
    "await assistant.delete_uploaded_files(cancellation_token)\n",
    "await assistant.delete_assistant(cancellation_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Executor Agent\n",
    "An agent that extracts and executes code snippets found in received messages and returns the output.\n",
    "\n",
    "It is typically used within a team with another agent that generates code snippets to be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import CodeExecutorAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.code_executors.docker import DockerCommandLineCodeExecutor\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "\n",
    "# Create a code executor agent that uses a Docker container to execute code.\n",
    "docker_code_executor = DockerCommandLineCodeExecutor(work_dir=\"coding\")\n",
    "\n",
    "# Start the docker code executor.\n",
    "await docker_code_executor.start()\n",
    "\n",
    "# Create a code executor agent.\n",
    "code_executor_agent = CodeExecutorAgent(\"code_executor\", code_executor=docker_code_executor)\n",
    "\n",
    "# Run the agent with a given code snippet.\n",
    "task = TextMessage(\n",
    "    content='''Here is some code\n",
    "    ```python\n",
    "print('Hello world')\n",
    "    ```\n",
    "    ''',\n",
    "    source=\"user\",\n",
    ")\n",
    "\n",
    "response = await code_executor_agent.on_messages([task], CancellationToken())\n",
    "print(response.chat_message)\n",
    "\n",
    "# Stop the docker code executor.\n",
    "await docker_code_executor.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
