{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel Multi Agent Collaboration\n",
    "\n",
    "This notebook will showcase how agents can communicate and collaborate to process complex tasks, such as generating and enhancing images through multiple iterations based on user input. \n",
    "\n",
    "Dalle Assistant - Creates images using Dall-e\n",
    "\n",
    "Vision Assistant - Critiques and provides a new enhanced prompt.\n",
    "\n",
    "Manager - Counts the number of Images Generated. The Manager will determine when the conversation should be terminated.\n",
    "\n",
    "## This uses the following Azure AI services:\n",
    "\n",
    "- Azure OpenAI Service\n",
    "- GPT-4 Turbo with Vision or higher - Any Azure OpenAI model that can analyze images and provide textual responses to questions about them.\n",
    "- Azure OpenAI Dall-e - A series of models in preview that can generate original images from natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dependencies\n",
    "Run in terminal\n",
    "- sudo apt-get update\n",
    "- sudo apt-get install -y libgl1-mesa-glx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Azure OpenAI Clients to be used by Plugins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncAzureOpenAI\n",
    "\n",
    "# Create the Dalle client\n",
    "dalle_client = AsyncAzureOpenAI(\n",
    "    api_key=azure_openai_key, \n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint\n",
    ")\n",
    "dalle_deployment_name = \"dall-e-3\"\n",
    "\n",
    "# Create the Vision client\n",
    "vision_client = AsyncAzureOpenAI(\n",
    "    api_key=azure_openai_key, \n",
    "    api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint\n",
    ")\n",
    "vision_deployment_name = \"gpt-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import requests\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import base64\n",
    "\n",
    "class GenerateImagePlugin:\n",
    "    \"\"\"Generates an Image Plugin\"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Generates or creates an image\")\n",
    "    async def generate_image(self, \n",
    "        prompt: Annotated[str, \"Prompt to generate an image coming from user and Vision Assistant\"]) -> Annotated[str, \"Displays a response that an image was generated\"]:\n",
    "        \"\"\"\n",
    "        Call the Azure OpenAI Dall-e 3 model to generate an image from a text prompt.\n",
    "        Executes the call to the Azure OpenAI Dall-e 3 image creator, saves the file into the local directory, and displays the image.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"\\n\" + \"Dalle Assistant Message: Creating the image ...\")\n",
    "\n",
    "        response = await dalle_client.images.generate(\n",
    "            model=dalle_deployment_name, prompt=prompt, size=\"1024x1024\", quality=\"standard\", n=1\n",
    "        )\n",
    "\n",
    "        # Retrieve the image URL from the response (assuming response structure)\n",
    "        image_url = response.data[0].url\n",
    "\n",
    "        # Open the image from the URL and save it to a temporary file.\n",
    "        im = Image.open(requests.get(image_url, stream=True).raw)\n",
    "\n",
    "        # Define the filename and path where the image should be saved.\n",
    "        filename = \"temp.jpg\"\n",
    "        local_path = Path(filename)\n",
    "\n",
    "        # Save the image.\n",
    "        im.save(local_path)\n",
    "\n",
    "        # Get the absolute path of the saved image.\n",
    "        full_path = str(local_path.absolute())\n",
    "\n",
    "        img = cv2.imread(\"temp.jpg\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        # Convert the image from BGR to RGB for displaying with matplotlib,\n",
    "        # because OpenCV uses BGR by default and matplotlib expects RGB.\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Display the image with matplotlib.\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.axis(\"off\")  # Turn off axis labels.\n",
    "        plt.show()\n",
    "\n",
    "        # Return the full path of the saved image.\n",
    "        print(\"Dalle Assistant Message: \" + full_path)\n",
    "        return \"Image generated successfully and store in the local file system. You can now use this image to analyze it with the vision_assistant\"\n",
    "    \n",
    "class AnalyzeImagePlugin:\n",
    "    \"\"\"Analyzes an Image Plugin\"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Analyzes and enhances an image\")\n",
    "    async def analyze_image(self) -> Annotated[str, \"Returns new prompt that enhances the image based on the criticism and analysis.\"]:\n",
    "        \"\"\"\n",
    "        Call the Azure OpenAI model to analyze and critic an image and return the result.\n",
    "        The resulting output should be a new prompt for dall-e that enhances the image based on the criticism and analysis\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"Vision Assistant Message: \" + \"Analyzing the image...\")\n",
    "\n",
    "        # Create a Path object for the image file\n",
    "        image_path = Path(\"temp.jpg\")\n",
    "\n",
    "        # Using a context manager to open the file with Path.open()\n",
    "        with image_path.open(\"rb\") as image_file:\n",
    "            base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "        content_images = [\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "            for base64_image in [base64_image]\n",
    "        ]\n",
    "        response = await vision_client.chat.completions.create(\n",
    "            model=vision_deployment_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"Analyze and critic this image and generate a new enhanced prompt for Dall-e with the criticism and analysis.\",\n",
    "                        },\n",
    "                        *content_images,\n",
    "                    ],\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "        print(\"Vision Assistant Message: \" + response.choices[0].message.content)\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "class CountPlugin:\n",
    "    \"\"\"Counts\"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Counts the number of images created by the Dalle Assistant\")\n",
    "    async def count_images(self,\n",
    "                            count: Annotated[int, \"number of images created by the Dalle Assistant\"]) -> Annotated[int, \"Returns the count number\"]:\n",
    "        print(\"Manager: The number of images created is: \" + str(count))\n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function to create a Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion import AzureChatCompletion\n",
    "from semantic_kernel.kernel import Kernel\n",
    "\n",
    "def _create_kernel_with_chat_completion(service_id: str) -> Kernel:\n",
    "    kernel = Kernel()\n",
    "    kernel.add_service(AzureChatCompletion(service_id=service_id))\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.functions.kernel_function_from_prompt import KernelFunctionFromPrompt\n",
    "from semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy import KernelFunctionSelectionStrategy\n",
    "from semantic_kernel.agents.strategies.termination.kernel_function_termination_strategy import KernelFunctionTerminationStrategy\n",
    "from semantic_kernel.agents import AgentGroupChat,  ChatCompletionAgent\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "DALLE_NAME = \"DalleAssistant\"\n",
    "VISION_NAME = \"VisionAssistant\"\n",
    "MANAGER_NAME = \"Manager\"\n",
    "TERMINATION_KEYWORD = \"yes\"\n",
    "\n",
    "### Manager Assistant\n",
    "# Create the instance of the Kernel\n",
    "manager_kernel = _create_kernel_with_chat_completion(MANAGER_NAME)\n",
    "manager_kernel.add_plugin(CountPlugin(), plugin_name=\"CountPlugin\")\n",
    "\n",
    "settings = manager_kernel.get_prompt_execution_settings_from_service_id(service_id=MANAGER_NAME)\n",
    "# Configure the function choice behavior to auto invoke kernel functions\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Required()\n",
    "\n",
    "# Create the agent\n",
    "manager_agent = ChatCompletionAgent(\n",
    "    service_id=MANAGER_NAME, \n",
    "    kernel=manager_kernel, \n",
    "    name=MANAGER_NAME, \n",
    "    instructions=f\"\"\"\n",
    "        Start with a count of 0.\n",
    "        Add the number of images created by the Dalle Assistant.\n",
    "        If count is 3, you will provide a termination message: {TERMINATION_KEYWORD}\n",
    "        \"\"\",\n",
    "    arguments=KernelArguments(settings=settings)\n",
    ")\n",
    "\n",
    "### DALLE Assistant\n",
    "# Create the instance of the Kernel\n",
    "dalle_assistant_kernel = _create_kernel_with_chat_completion(DALLE_NAME)\n",
    "dalle_assistant_kernel.add_plugin(GenerateImagePlugin(), plugin_name=\"GenerateImagePlugin\")\n",
    "\n",
    "settings = dalle_assistant_kernel.get_prompt_execution_settings_from_service_id(service_id=DALLE_NAME)\n",
    "# Configure the function choice behavior to auto invoke kernel functions\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Required()\n",
    "\n",
    "# Create the agent\n",
    "dalle_assistant_agent = ChatCompletionAgent(\n",
    "    service_id=DALLE_NAME, \n",
    "    kernel=dalle_assistant_kernel, \n",
    "    name=DALLE_NAME, \n",
    "    instructions=\"\"\"\n",
    "        As a premier AI specializing in image generation, you possess the expertise to craft precise visuals based on given prompts. \n",
    "        It is essential that you diligently generate the requested image, ensuring its accuracy and alignment with the user's specifications, \n",
    "        prior to delivering a response.\n",
    "        You will have access to the local file system to store the generated image.\n",
    "        You will generate an image based on the user's prompt and display it for review.\n",
    "        You will generate new images based on the feedback from the Vision Assistant.\n",
    "        \"\"\", \n",
    "    arguments=KernelArguments(settings=settings)\n",
    ")\n",
    "\n",
    "### Vision Assistant\n",
    "# Create the instance of the Kernel\n",
    "vision_assistant_kernel = _create_kernel_with_chat_completion(VISION_NAME)\n",
    "vision_assistant_kernel.add_plugin(AnalyzeImagePlugin(), plugin_name=\"AnalyzeImagePlugin\")\n",
    "\n",
    "settings = vision_assistant_kernel.get_prompt_execution_settings_from_service_id(service_id=VISION_NAME)\n",
    "# Configure the function choice behavior to auto invoke kernel functions\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Required()\n",
    "\n",
    "# Create the agent\n",
    "vision_assistant_agent = ChatCompletionAgent(\n",
    "    service_id=VISION_NAME, \n",
    "    kernel=vision_assistant_kernel, \n",
    "    name=VISION_NAME, \n",
    "    instructions=\"\"\" \n",
    "        As a leading AI expert in image analysis, you excel at scrutinizing and offering critiques to refine and improve images. \n",
    "        Your task is to thoroughly analyze an image, ensuring that all essential assessments are completed with precision \n",
    "        before you provide feedback to the user. You have access to the local file system where the image is stored.\n",
    "        You will analyze the image and provide a new prompt for Dall-e that enhances the image based on the criticism and analysis.\n",
    "        You will then instruct the Dall-e Assistant to generate a new image based on the new prompt.\n",
    "        \"\"\", \n",
    "    arguments=KernelArguments(settings=settings)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Selection Function, Termination Function, and Agent Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"selection\",\n",
    "    prompt=f\"\"\"\n",
    "        Determine which participant takes the next turn in a conversation based on the most recent participant.\n",
    "        State only the name of the participant to take the next turn.\n",
    "        Choose only from these participants:\n",
    "        - {DALLE_NAME}\n",
    "        - {VISION_NAME}\n",
    "        - {MANAGER_NAME}\n",
    "        \n",
    "        You will follow this sequence:\n",
    "        Step 1: {DALLE_NAME} will generate an image based on the initial user prompt and display it for review.\n",
    "        Step 2: {VISION_NAME} will analyze the image and provide a new prompt for {DALLE_NAME} to generate a new image based on the new prompt.\n",
    "        Step 3: {DALLE_NAME} will generate an image based on the {VISION_NAME} prompt and display it for review.\n",
    "        Step 4: {VISION_NAME} will analyze the image and provide a new prompt for {DALLE_NAME} to generate a new image based on the new prompt.\n",
    "        Step 5: Repeat steps 3-4 until conversation is terminated.\n",
    "        \n",
    "        {MANAGER_NAME} counts the number of images created by {DALLE_NAME}. If the count is 3, {MANAGER_NAME} will provide a termination message.\n",
    "        \n",
    "        No participant should take more than one turn in a row.\n",
    "\n",
    "        History:\n",
    "        {{{{$history}}}}\n",
    "        \"\"\",\n",
    ")\n",
    "\n",
    "termination_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"termination\",\n",
    "    prompt=f\"\"\"\n",
    "        When {MANAGER_NAME} provices the termination keyword {TERMINATION_KEYWORD}, respond with the termination keyword: {TERMINATION_KEYWORD}\n",
    "        RESPONSE:\n",
    "        {{{{$history}}}}\"\"\"\n",
    ")\n",
    "\n",
    "chat = AgentGroupChat(\n",
    "    agents=[dalle_assistant_agent, vision_assistant_agent, manager_agent],\n",
    "    selection_strategy=KernelFunctionSelectionStrategy(\n",
    "        function=selection_function,\n",
    "        kernel=_create_kernel_with_chat_completion(\"selection\"),\n",
    "        result_parser=lambda result: str(result.value[0]) if result.value is not None else DALLE_NAME or VISION_NAME,\n",
    "        agent_variable_name=\"agents\",\n",
    "        history_variable_name=\"history\"\n",
    "    ),\n",
    "    termination_strategy=KernelFunctionTerminationStrategy(\n",
    "        agents=[manager_agent],\n",
    "        function=termination_function,\n",
    "        kernel=_create_kernel_with_chat_completion(\"termination\"),\n",
    "        result_parser=lambda result: TERMINATION_KEYWORD in str(result.value[0]).lower(),\n",
    "        history_variable_name=\"history\",\n",
    "        maximum_iterations=10,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Generate an image of a boat drifting in the water, with a sunset in the background\"\n",
    "await chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "try:\n",
    "    async for response in chat.invoke():\n",
    "        print(f\"# {response.role} - {response.name or '*'}: '{response.content}'\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async for message in chat.get_chat_messages():\n",
    "    print(f\"{message.to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset the Agent Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate if completion is met and reset\n",
    "if chat.is_complete:\n",
    "    # Reset completion state to continue reuse of chat.\n",
    "    chat.is_complete = False\n",
    "\n",
    "#reset the chat\n",
    "await chat.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async for message in chat.get_chat_messages():\n",
    "    print(f\"{message.to_dict()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
